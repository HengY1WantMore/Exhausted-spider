##  Exhausted-spider

> 一位肚皮朝天的的蜘蛛。爬虫千千万万，我要走属于自己的一条。
>
> 现在每个网站防御体制不同，只有不断的磨练，才能爬虫学的好。
>
> 鄙人一位暨南大学20本科生，在计算机的道路上越走越远。
>
> 欢迎私信我，与我交流，2911567026@qq.com邮件先联系。

***

##   介 绍

###  前言：

>  为了将每个demo联系起来，采用了仿AOP分层架构，进行了面向对象的再次加工。
>
> 可以将整个项目克隆下来，然后在对应的层直接进行操作。
>
> 所有涉及代理，均采用的clash的7890端口，请自己的梯子小改。
> 
> 普遍的过程为：
>
> - 筛选有效链接
> - 内容的提取与匹配
> - 整理并且记录结果
> - 人工选择


##  项目目录

>```
>├─control  // 业务层
>│  ├─Demo
>│  ├─...
>│
>├─data  // 数据处理层
>│  ├─Demo
>│  ├─...
>│
>├─demo  //示例
>│  ├─抓取今日头条
>│  ├─抓取微信文章
>│  ├─抓取每日简报
>│  ├─抓取猫眼电影Top100
>│  └─模拟浏览器抓取淘宝
>│
>├─tool // 工具
>│  ├─font  // 繁体字与简体字的转换
>│  ├─baiduSearch  // 百度搜索
>│  ├─googleSelenium  // 谷歌模拟器搜索
>│  ├─seleImitation  // 模拟器筛选操作
>│  ├─wikiSearch // 维基百科搜索
>│
>├─common 公共层
>│
>├─database 数据库操作
>└─
>```

###  如何使用

> 首先在业务层直接创建对应的任务
>
> 其次根据自己需要引入相关文件
>
> 根据python使用类的规范以及操作对应的函数进行操作
>
> 通过此，能达到快速数据的获取
>
> 然后到数据层下进行对筛选数据的操作
>
> 在数据层可以转换数据类型，处理图片，保存内容等
>
> 最后达到的效果是根据实际情况快速爬虫

###  计划

> - 指定页数翻页查询
> - ban掉禁用词语

##  拓展

- 代理池 https://github.com/Python3WebSpider/ProxyPool
- 繁体字-简体字互相转换 https://github.com/skydark/nstools/tree/master/zhtools
- flashtext 寻找关键词 https://github.com/vi3k6i5/flashtext

##  库

```python
pip install -r requirements.txt
```



